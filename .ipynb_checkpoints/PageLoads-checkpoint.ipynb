{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Function to download analytics data for all navigation links on the website\n",
    "# Parses through the HTML navigation bar and uses the extension to download data\n",
    "def endPointHits(websiteURL, userDir, extensionPath, driverPath):\n",
    "    \"\"\"\n",
    "        websiteURL: URL for the page to be analysed\n",
    "        userDir: system path for user's directory (eg. '/Users/JohnDoe')\n",
    "        extensionPath: system path for unpacked Adobe extension \n",
    "            (eg. '/Users/JohnDoe/Documents/data-bot/adobe-debugger')\n",
    "        driverPath: system path for Chrome driver\n",
    "            (eg. '/Users/JohnDoe/Documents/data-bot/chromedriver')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a Beautiful Soup Object with website's\n",
    "    # Home page HTML\n",
    "    response = get(websiteURL)\n",
    "    htmlSoup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # print(html_soup.prettify())\n",
    "\n",
    "    # Finding all navigation links for page load testing\n",
    "    endPoints = []\n",
    "    navLinks = htmlSoup.find('nav').find_all('a')\n",
    "    \n",
    "    for link in navLinks:\n",
    "        # value of href attribute of each tag\n",
    "        href = link.get('href')\n",
    "\n",
    "        if href != None:\n",
    "            # checking for full links vs end points\n",
    "            if href.find('http') == -1: \n",
    "                href = websiteURL + href\n",
    "            # Standardizing URL\n",
    "            if href[-1] == '/':\n",
    "                href = href[:-1]\n",
    "\n",
    "            endPoints.append(href)\n",
    "\n",
    "    # Remove duplicate links\n",
    "    endPoints = list(dict.fromkeys(endPoints))\n",
    "\n",
    "    # Exporting web endpoints to a CSV file\n",
    "    with open(userDir + '/Downloads/Endpoints.csv', 'w') as f:\n",
    "        # Joining links with newline delimiter to create rows\n",
    "        f.write('\\n'.join(endPoints))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # Loads modified Adobe extension from directory and adds it to Selenium instance. \n",
    "    unpacked_extension_path = extensionPath\n",
    "    options = Options()\n",
    "\n",
    "    options.add_argument('--load-extension={}'.format(unpacked_extension_path))\n",
    "    driver = webdriver.Chrome(driverPath, options=options)\n",
    "\n",
    "    # Downloading Page Load analytics for each page in CSV format\n",
    "    for page in endPoints:\n",
    "        driver.get(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
